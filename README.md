# ðŸ“š Traditional Information Retrieval System

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?style=for-the-badge&logo=python&logoColor=white)
![Code Style](https://img.shields.io/badge/Code%20Style-Black-black?style=for-the-badge)
![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)

## ðŸ“– Overview

This project implements fundamental **Information Retrieval (IR)** algorithms from scratch to fetch relevant documents for ad-hoc user queries. The system explores and compares three major probabilistic and heuristic models:

1.  **BM25**: A robust, industry-standard probabilistic retrieval framework.
2.  **Unigram Language Model**: Uses Dirichlet Smoothing to estimate document generation probabilities.
3.  **Bigram Language Model**: Leverages Linear Interpolation to capture word-pair context and dependency.

The goal is to analyze how considering term dependency (Bigram) and smoothing techniques impacts retrieval performance compared to the classic BM25 baseline.

---

## ðŸ“‘ Table of Contents
- [Overview](#-overview)
- [Key Features](#-key-features)
- [Installation](#-installation)
- [Usage](#-usage)
- [Project Structure](#-project-structure)
- [Experimental Results](#-experimental-results)
- [License](#-license)

---

## ðŸš€ Key Features

*   **Custom Tokenization**: Specialized text preprocessing pipeline.
*   **Vectorized Implementation**: Efficient NumPy-based calculations for scoring.
*   **Hyperparameter Tuning**: Grid search implementation for:
    *   BM25: $k_1$ and $b$
    *   Unigram: $\mu$ (Dirichlet)
    *   Bigram: $\lambda$ (Interpolation)
*   **Evaluation Metrics**: Custom implementations of **MAP**, **MRR**, and **P@5**.

---

## ðŸ›  Installation

### Prerequisites
Ensure you have Python 3.10 or higher installed.

### 1. Clone the Repository
```shell
git clone https://github.com/your-username/traditional-retrieval.git
cd traditional-retrieval
```
### 2. Set up a Virtual Environment (Recommended)
```Shell
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```
### 3. Install Dependencies
```Shell
pip install -r requirements.txt
```
### 4. Install Dev Dependencies (Optional)
If you wish to contribute or run linting tools:
```Shell
pip install -r dev-requirements.txt
pre-commit install
```
## ðŸ’» Usage
To run the complete pipeline (preprocessing, tuning, training, and evaluation), execute the main run script:
```Shell
python -m pipeline.run
```
Ensure your dataset files are placed in the resources/ directory as configured in src/config_loader.py.
## ðŸ“‚ Project Structure

```Text
.
â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ run.py             # Main entry point for the pipeline
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ bm25_retriever.py  # BM25 Logic
â”‚   â”œâ”€â”€ language_retriever.py # Unigram & Bigram Logic
â”‚   â”œâ”€â”€ fine_tuning.py     # Hyperparameter grid search
â”‚   â”œâ”€â”€ metrics.py         # Evaluator (MAP, MRR, P@5)
â”‚   â”œâ”€â”€ utils.py           # Tokenization and helpers
â”‚   â””â”€â”€ ...
â”œâ”€â”€ resources/
â”‚   â”œâ”€â”€ raw/               # Dataset JSON files
â”‚   â””â”€â”€ vocab/             # Generated vocabulary artifacts
â”œâ”€â”€ imgs/                  # Result plots
â””â”€â”€ README.md
```
## ðŸ“Š Experimental Results
We evaluated the models on a test dataset containing ad-hoc queries. The Bigram Model demonstrated superior performance across all metrics, highlighting the importance of capturing phrase-level context.

| retriever         |P@5       |MRR       |MAP        |
| ------------------|----------|----------|-----------|
|BM25               |0.233     |0.366     |0.095      |
|Unigram            |0.253     |0.413     |0.092      |
|Bigram             |0.313     |0.509     |0.129      |

## Visualization
The following chart illustrates the performance gap between the methods:
![alt text](imgs/results.png)
## ðŸ“œ License
This project is licensed under the MIT License.